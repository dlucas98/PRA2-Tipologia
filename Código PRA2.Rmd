---
title: "PRA2-Tipologia"
author: "David Lucas, Francisco Javier Cantero"
date: "25/5/2022"
output: 
  pdf_document:
    number_sections: yes
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# PAQUETES
if (!require('nortest')) install.packages('nortest'); library('nortest')
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
if (!require('pROC')) install.packages('pROC'); library('pROC')
if (!require('ResourceSelection')) install.packages('ResourceSelection'); library('ResourceSelection')
if (!require('caret')) install.packages('ResourceSelection'); library('caret')
```

# Descripción del dataset  

Para llevar a cabo el desarrollo de esta práctica, se utilizará el dataset obtenido en la Práctica 1. Este dataset contiene datos de cada uno de los jugadores que hayan interactuado con la NBA durante un periodo de tiempo específico (última temporada) y recoge todas las estadísticas acumuladas. Adicionalmente, el dataset incluye la variable PER (player efficiency rating) que permite evaluar la eficiencia del jugador con respecto a las estadísticas totales de la temporada. Mediante esta variable, se podrá conocer cómo ha sido el rendimiento del jugador y poder comparar con el resto de jugadores de una manera rápida y sencilla. Por lo tanto, el dataset incluye un total de 19 campos:

* Nombre: Indica el nombre del jugador.
* Equipo: Indica el nombre del equipo al que pertenece el jugador.
* MP: (Minutes played) Indica los minutos que ha jugado en total un jugador.
* FG: (Field goals) Indica los tiros de campo anotados (sin contar los tiros libres).
* FGA: (Field goal attempts) Indica los tiros de campo realizados (sin contar los tiros libres).
* FG3: (3-point field goals) Indica los tiros de tres puntos anotados por el jugador.
* FG3A: (3-point field goal attempts) Indica los tiros de tres puntos realizados por el jugador.
* FT: (Free throws) Indica los tiros libres anotados por el jugador.
* FTA: (Free throw attempts) Indica los tiros libres realizados por el jugador.
* ORB: (Offensive rebounds) Indica los rebotes ofensivos capturados por un jugador.
* DRB: (Defensive rebounds) Indica los rebotes defensivos capturados por un jugador.
* AST: (Assists) Indica las asistencias realizadas por un jugador.
* STL: (Steals) Indica los robos realizados por jugador.
* BLK: (Blocks) Indica los tapones realizados por el jugador.
* TOV: (Turnovers) Indica las pérdidas realizadas por el jugador.
* PF: (Personal fouls) Indica las faltas personales realizadas por el jugador.
* PTS: (Points) Indica el total de puntos anotados por el jugador.
* G: (Games) Indica los partidos totales jugados por el jugador.
* PER: (Player efficiency rating) Detalla la eficiencia del jugador haciendo uso de las estadísticas anteriores.

Para finalizar, este conjunto de datos es importanto, ya que representa la volumetría general de diferentes apartado estadísticos durante la temporada 2020-2021 lo que nos permitirá poder conocer en mayor profundidad los jugadores que componen la liga.

# Integración y selección de los datos de interés a analizar

Para comenzar con el tratamiento de los datos, se realiza la carga del dataset creado en la primera práctica de la asignatura:

```{r}
playerstats <- read.csv("NBAPlayerStatistics_20-21.csv", stringsAsFactors = FALSE)
head(playerstats,3)
```

Una vez cargada la información, mostramos la cabecera de este. En los primero registros del conjunto de datos podemos observar que el jugador Aaron Gordon se encuentra dos veces debido a que el jugador fue traspasado de un equipo a otro durante el transcurso de la temporada. Ante esta situación, se ha decidido matener los dos registros ya que la información que refleja cada uno de estos se ve influida por el contexto del equipo en el que jugó el jugador.

Además del conjunto de datos creado en la prácitca anterior, se ha decidido incluir a este información adicional proveniente del conjunto de datos Nba 2020-2021 Season Player Stats del repositorio de Kaggle (https://www.kaggle.com/datasets/umutalpaydn/nba-20202021-season-player-stats?resource=download). Por lo tanto, se pasa a realizar la carga de este conjunto de datos adicional:

```{r}
playerstats2 <- read.csv("nba2021_advanced.csv", stringsAsFactors = FALSE)
summary(playerstats2)
```

De este conjunto de datos, se ha decidido seleccionar las variales de posición (POS) y edad (Age) ya que estas enriquecen el conjunto de datos creado en la primera práctica de la asignatura. Por lo tanto, se pasa a realizar la asignación a cada jugador de su posición y edad durante la temporada 2020-2021:


```{r}
# playerstats["Age"] <- playerstats2$Age[playerstats2$Player == playerstats$Nombre]
playerstats["Age"] <- NULL
playerstats["Pos"] <- NULL
for (i in 1:length(playerstats$Nombre)){
  for (j in 1:length(playerstats2$Player))
    if(playerstats$Nombre[i] == playerstats2$Player[j]){
      playerstats$Age[i] <- playerstats2$Age[j]
      playerstats$Pos[i] <- playerstats2$Pos[j]
    }
}
playerstats <- playerstats[,c(1,2,20,21,3:19)]
```


Una vez asignadas la posición y la edad a cada jugador, se pasa a realizar la reducción de variables. Analizando en conjunto de datos, podemos observar que en este se almacenan los volumenes de tiro de los jugadores, como por ejemplo, FG3 y FG3A que muestran el volumen de tiros de tres puntos anotados y lanzados. Es por esto que se ha decido reducir estas dos variables a una sola mediante el cálculo del porcentaje de tiro de tres puntos. Por lo tanto, esta reducción se realizará con respecto a los tiros de tres puntos, tiros de dos puntos y tiros libres:


```{r}
playerstats["FG2p"] <- round((playerstats["FG"] - playerstats["FG3"]) / (playerstats["FGA"] - playerstats["FG3A"]), 2)
playerstats["FG3p"] <- round(playerstats["FG3"] / playerstats["FG3A"], 2)
playerstats["FTp"] <- round(playerstats["FT"] / playerstats["FTA"], 2)
```

Para finalizar con la construcción del conjunto de datos final, se pasa a reordenar las variables para que estas mantengan el orden visual en el conjunto de datos:

```{r}
playerstats <- playerstats[,c(1:5,20,22:24,12:19,21)]
```

Para finalizar con este apartado, se muestra el resumen del conjunto de datos y la cabecera de este:
```{r}
# Resumen del conjunto de datos
summary(playerstats)
# Cabecera del conjunto de datos
head(playerstats,3)
```

# Limpieza de los datos

## Ceros y elementos vacíos

Se pasa a continuación a realizar la comprobación de valores nulos y vacíos dentro del conjunto de datos. En primer lugar, se comprueba la existencia de valores NaN dentro de este: 

```{r}
colSums(is.na(playerstats))
```

Como podemos observar, en las variables creadas anteriormente, que reflejan los porcentajes de tiro, estas contienen valores NaN producto de los cálculos realizados anteriormente. Para su corrección, se va a asignar a estos valores el valor de 0.00 debido a que es al que hacen referencia:

```{r}
playerstats$`FG2p`[is.na(playerstats$`FG2p`)] <- 0.00
playerstats$`FG3p`[is.na(playerstats$`FG3p`)] <- 0.00
playerstats$`FTp`[is.na(playerstats$`FTp`)] <- 0.00
# Comprobación de que ya no hay valores NaN 
colSums(is.na(playerstats))
```

Como se puede observar, estos valores han sido eliminado del conjunto de datos. Por último, se pasa a realizar la comprobación de valores vacíos dentro de las variables:

```{r}
colSums(playerstats==""|playerstats==" ")
```

Con respecto a los valores vacíos, se puede observar que no existen. Por lo tanto, no es necesario realizar ninguna acción para su corrección.  

## Identificación y gestión de valores extremos

Se pasa a continuación a realizar la detección de outliers dentro del conjunto de datos. Para ello, únicamente se va a realizar esta detección sobre las variables que representan los minutos jugados (MP) y los partidos (G). El motivo de detectar únicamente en estas dos variables si existen outliers se debe a que por un lado podremos analizar si existen jugadores que han jugados pocos minutos o partidos en la liga con respecto al resto de jugadores, y en caso de existir, podremos eliminarlos para que no afecten a los análisis que se realizaran posteriormente. Dicho esto, se pasa a visualizar los diagramas de cajas de las variables anteriormente mencionadas:

```{r}
# Diagramas de caja
par(mfrow = c(1, 2))
box_MP <- boxplot(playerstats$MP,main="MP outliers")
box_G <- boxplot(playerstats$G,main="G outliers")
```

Como se puede observar, en ambos diagramas no existen outliers. Sin embargo, estos diagramas son útiles ya que a traves del primer percentil se puede realizar el filtro de los jugadores que han jugado pocos minutos o partidos. Por lo tanto, a partir de este se pasa a realizar la eliminación de los jugadores que en la variables MP y G, se encuentran por debajo de este percentil:

```{r}
# Percential 25 de ambas variables
box_MP$stats[2]
box_G$stats[2]
# Eliminación de registros por debajo de este percentil
playerstats <- playerstats[playerstats$MP > box_MP$stats[2],]
playerstats <- playerstats[playerstats$G > box_G$stats[2],]
```

Una vez hecho esto, el conjunto de datos obtenido y con el que se va a pasar a realizar los análisis contiene la siguiente información:

```{r}
# Resumen del conjunto de datos
summary(playerstats)
# Cabecera del conjunto de datos
head(playerstats)
```

# Análisis de los datos

## Selección de los grupos de datos que se quieren analizar/comparar

Con respecto a la selección de los grupos de datos, esta se va a realizar en cada análisis para no perder el hilo durante la realización de estos. Sin embargo, se pasa a comentar que conjuntos de datos se van a tener en cuenta y que análisis se van a realizar sobre estos:

* *Estudio de correlaciones lineales.* Este estudio permite asegurarse de la dependencia/independecia entre las variables que componen el conjunto de datos creado en los apartados anteriores. El objetivo de este análisis es conocer que variables tienen una mayor relevancia a la hora de calcular el PER y nos ayudará a descartar aquellas variables que no lo definen. Para ello, el conjunto de datos que se utilizará estará compuesto por la variables numéricas estadísticas que componen el conjunto de datos construido durante esta práctica.
* *Regresión lineal.* Con respecto al análisis de regresión lineal se va a realizar la creación de dos modelos que permitan calcular el valor del PER a partir de esto. El primero de estos modelos, hará uso de las variables numéricas estadísticas y en el segundo se añadirá la edad del jugador para conocer si esta influye en el valor del PER. Por lo tanto, el conjunto de datos que se utilizará para este análisis será el compuesto por las variables numéricas del conjunto de datos contruido durante la práctica a excepción de las variables FP y PTS ya que no intervienen en el PER.
* *Regresión logistica.* Mediante la creación de un modelo de regresión logistica, se va a proceder a saber si un jugador puede ser categorizado como grande o pequeño en función de sus apartados estadísticos. Por lo tanto, el conjunto de datos que se utilizará para este análisis será el compuesto por las variables numéricas del conjunto de datos contruido durante la práctica a excepción de las variables FP y PTS ya que no intervienen en el PER.
* *Contraste de hipótesis.* A partir del contraste de hipótesis se va a proceder a comprobar si es verdad la creencia generalizada en el mundo del baloncesto de que los jugadores que juegan en la posición de CENTER tienen un mayor PER que los que juegan en el resto de posiciones. Para ello, se va a proceder a la creación de dos conjuntos de datos en los que en el primero solo se incluyan los jugadores que juegan en la posición de CENTER y las variables estadísticas numéricas que hayan obtenido, y en el segundo, la de los jugadores del resto de posiciones.

Estos seran los conjuntos de datos y los análisis que se procederan a realizar a continuación.

## Comprobación de la normalidad y homogeneidad de la varianza

### Comprobación de la normalidad

Para realizar la comprobación de la normalidad, se va a realizar el estudio sobre las variables numéricas que se utilizarán posteriormente en los modelos. Es decir, la variables sobre las cuales se procede a estudiar la normalidad y la homogeneidad de la varianza que son *FG2p*, *FG3p*, *FTp*, *ORB*, *DRB*, *AST*, *STL*, *BLK*, *TOV*, *PF*, *PTS*, *PER*:  

```{r}
par(mfrow=c(3,4))
for(i in 7:ncol(playerstats)) {
  qqnorm(playerstats[,i],main = paste(colnames(playerstats)[i]))
  qqline(playerstats[,i],col="red")
  
  x <-playerstats[,i]
  plot(density(x), main=bquote(~ n == .(playerstats[,i])),
       ylab='Densidad', col='blue3', xlab='x', las=1, lwd=4)
  
  
}
```

Como se puede observar, tenemos variables que, mediante los gráficos Q-Q y de densidad, podemos concluir que siguen una distribución bastante normal. Estas variables serían FG2p, FTp, PF y PER. El resto, se alejan un poco de la simetría que se buscaría en este tipo de distribuciones aunque tampoco se podría descartar al 100% la normalidad. Para confirmar esto, se podrían realizar tests de normalidad como el de Shapiro, pero al tener una cantidad de muestras muy grande (superior a 30), no nos podemos fiar demasiado de estos resultados.

```{r}
for(i in 7:ncol(playerstats)) {
  print(paste("Tests de ", colnames(playerstats)[i]))
  print(shapiro.test(x)$p.value)  
}
```

Se aprecia que según estos tests ningúna variable sigue una distribución normal, ya que nos indica en todas que el p-value es menor que el coeficiente 0.05 y nos indicaría que se puede rechazar la hipótesis nula, lo que en resumen significaría que no siguen una distribución normal. Sin embargo, teniendo en cuenta que tenemos 437 muestras, se puede aplicar el Teorema del Límite Central, que establece que el contraste de hipótesis sobre la media de una muestra se aproxima a una distribución normal aunque la población original no siga una distribución normal, siempre que el tamaño de la muestra sea suficientemente grande.


### Homogeneidad de la varianza

Para la homogeneidad de la varianza, se va a hacer uso del test de Fligner-Killeen para su estudio. En este estudio, se va a comparar todas las variables con la variable del PER ya que esta se extrae de las anteriores. Por lo tanto, suponiendo que la hipótesis nula consiste en que ambas varianzas son iguales, se procede a aplicar el test:  

```{r}
for(i in 7:(ncol(playerstats)-1)) {
print(paste('Test sobre la homogeneidad',colnames(playerstats)[i],' - PER'))
flitest <- fligner.test(playerstats[,i] ~ PER, data = playerstats)
print(flitest$p.value)
}
```

Como se puede observar, practicamente todas las variables son homogeneas con la variable PER ya que el p-valor es superior a 0.05. Las variables que no son homogeneas son PTS y TOV que a pesar de estar por debajo se acercan mucho. Los resultados obtenidos, nos seran útiles para los test posteriores sobre el contraste de hipótesis donde tendremos que saber si las varianzas son igual o no.

## Aplicación de pruebas estadísticas para comparar los grupos de datos

### Estudio de correlaciones lineales

El estudio de correlaciones pretende determinar si dos variables están relacionadas[2]. El resultado del análisis es un coeficiente de correlación que tomará valores entre -1 y +1.  Si el signo es positivo, indica que si una variable aumenta, la otra también, ya que existe una relación positiva entre las dos variables. Si el signo es negativo indica que la relación es negativa y mientras los valores de una variable incrementan, los de la otra disminuyen. En cambio, Si las variables son independientes, el coeficiente de correlación será 0. La fuerza de la relación lineal incrementa a medida que el coeficiente de correlación se aproxima a -1 o a +1 y disminuye cuanto más se acerque al 0.

Ninguna de las variables explicativas puede ser combinación lineal de las otras, ya que en este caso no tendríamos un modelo de k variables, sino de k-1 variables (queremos que las variables Xi sean independientes). Debido a la naturaleza de los datos de nuestro conjunto, no sera necesario comprobar si existe una dependencia lineal entre las variables predictoras:

```{r}
x <- playerstats[7:18]
y <- playerstats[18]
cor_mat <- cor(y, x, use = "complete.obs")
cor_mat
```

Tras ejecutar la función *cor()*, podemos ver las correlaciones que existen entre la variable PER y las demás variables numéricas. Primeramente vemos que la variable más independiente, es decir, donde el coeficiente de correlación es 0 o lo más próximo, es en el porcentaje de tiros de 3 puntos (FG3p), donde el resultado es -0.0147. Sin embargo, el resto de variables tienen relaciones positivas, lo que significa que si aumentan, hacen aumentar el PER, lo cual tiene sentido teniendo en cuenta lo que representan. La variable que parece tener una mayor relación con el PER es la de los puntos anotados, que aunque no se utilicen para calcularlo, también acaban representando el rendimiento de un jugador. Otras variables que muestran una gran relación con el PER son las de TOV, DRB y AST, que se mantienen por encima de 0.5 en positivo. Tiene sentido que estas variables tengan relaciones altas debido a que es más probable que cualquier jugador de cualquier posición pueda destacar por ello, mientras que las variables de anotar puntos o realizar faltas pierden importancia a la hora de describir el PER de todas las posiciones.

Gracias a este análisis podríamos llegar a descartar la variable FG3p ya que parece tener poca importancia, pero se acabará de comprobar si este resultado también se refleja en los análisis predictivos que se realizarán a continuación.  


### Regresión lineal

Debido a que la variable de PER, se calcula a partir de la variables ORB, DRB, AST, STL, BLK, TOV y los volumenes de tiro. A continuación, se va a crear un modelo de regresión lineal el cual nos permita conocer que variables de las que tenemos en el conjunto de datos tienen una mayor importancia a la hora de realizar predicción del PER haciendo uso de este tipo de regresión. Es por esto que en primer lugar, se construye el modelo con las variables anteriormente comentadas y los porcentajes de efectivias en el tiro de los jugadores:

```{r}
regresion_l <- lm(PER ~ FG2p+FG3p+FTp+ORB+DRB+AST+STL+BLK+TOV, data = playerstats)
summary(regresion_l)
```

Como se puede observar las variables que tienen una mayor relevancia a la hora de obtener el PER según el modelo creado son las variables FG2p, FTp, ORB, AST y STL. Adicionalmente, podemos observar que el modelo creado tiene un coeficiente de determinación de 0.56 lo que nos permite suponer que el modelo ajusta a más de la mitad de los datos. Para poder confirmar esta suposición se pasa a realizar la visualización del grafico de los residuos y QQ con el que podremos entender de forma visual como se ajusta el modelo a los datos:

```{r}
par(mfrow = c(1, 2))
plot(regresion_l,which = 1)
plot(regresion_l,which = 2)
```

Como se puede observar, la suposición anterior es cierta y el modelo representa más de la mitad de los datos de conjunto de datos. Adicionalmente, se va a crear un modelo que a las variables anteriormente utilizadas al que se le incluya la variable de Age que representa la edad del jugador con el fin de conocer si la edad de un jugador es tiene relevancia a la hora de que un jugador tenga un mayor PER o no:

```{r}
regresion_l_age <- lm(PER ~ FG2p+FG3p+FTp+ORB+DRB+AST+STL+BLK+TOV+Age, data = playerstats)
summary(regresion_l_age)
```

Como se puede observar, la inclusión de la variable Age en el modelo no tiene una gran relevancia ya que este mejora muy levemente con un coeficiente de determinación de 0.56. Por lo tanto, para la siguiente parte del análisis, se va a hacer uso del primer modelo creado ya que no se aprecia casi mejoría. Por lo tanto, la recta de regresión del primer modelo creado es la siguiente:

$$
  y = -6.9301 + 22.4763x_1 + 2.7066x_2 + 10.0536x_3 + 0.0312x_4 - 0.0009x_5 + 0.0175x_6 - 0.0554x_7 + 0.0280x_8 + 0.0262x_9
$$

Para finalizar, se va a proceder a realizar una predicción haciendo uso del primer modelo. Para ello, se va a selecciónar el primero y el séptimo de los registros y se va a comprobar si el PER del conjunto de datos es similar al PER calculado por el modelo:

```{r}
seleccion_1 <- playerstats[1,]
pred <- predict(regresion_l, seleccion_1[7:15], type ="response")
print(paste('PER al calculado del jugador 1:',round(head(pred),2)))
print(paste('PER original del jugador 1:',seleccion_1[1,18]))
seleccion_2 <- playerstats[7,]
pred <- predict(regresion_l, seleccion_2[7:15], type ="response")
print(paste('PER calculado del jugador 2:',round(head(pred),2)))
print(paste('PER original del jugador 2:',seleccion_2[1,18]))
```

Como podemos observar, para el primer jugador, se obtiene un PER casi idéntico pero para el segundo esta diferencia se amplía a 2.5. Por lo tanto, y como se había visualizado, el modelo no se ajusta a todos los datos del conjunto de datos.  


### Regresión logística

Como segundo análisis, sobre el conjunto de datos, se ha decidido realizar un modelo de regresión logística el cual nos permita conocer que según sus estadísticas el jugador en cuestión es pequeño (Guard - G, Point Guard - PG, Small Guard - SG o Small Forward - SF) o grande (Paint Forward- PF o Center - C). Para ello, en primer lugar, se va a realizar la creación de una nueva variable llamada *tamanyo* la cual identifique si un jugador por su posición es pequeño o grande:
```{r}
playerstats$tamanyo<-"Small"
playerstats$tamanyo[playerstats$Pos=="C" | playerstats$Pos=="PF"] <- "Big"
playerstats$tamanyo <- as.factor(playerstats$tamanyo)
```

Una vez creada esta nueva variable y factorizada, se pasa a crear el modelo de regresión logística el cual nos permita conocer si un jugador es pequeño o grande según sus estadísticas:

```{r}
regresion_log <- glm(formula=tamanyo~FG2p+FG3p+FTp+ORB+DRB+AST+STL+BLK+TOV, data = playerstats, family=binomial(link=logit))
summary(regresion_log)
```

Tras la creación del modelo, se va a pasar a predecir con este, el tamaño de los jugadores según sus estadísticas. Para ello, se hará uso de la matriz de confusión para la obtención de resultados:

```{r}
playerstats$PROB_PRED <- round(predict(regresion_log, newdata = playerstats, "response"),4)
playerstats$TAM_PRED <- ifelse(playerstats$PROB_PRED > 0.5, "Small", "Big")
y_pred <- as.factor(playerstats$TAM_PRED)
y_obs <- as.factor(playerstats$tamanyo)
confusionMatrix(data=y_pred, reference = y_obs,  positive="Small")
```
Como se puede observar, el modelo ha tenido una precisión del 83% aproximadamente y ha clasificado correctamente 138 jugadores como hombres grandes y 225 como pequeños según su posición. Para finalizar, se muestra la distribución de los casos clasificados correctamente e incorrectamente por el modelo creado:
```{r}
Tabla <-  table(y_obs, y_pred)
barplot(Tabla, main="Matriz de confusión",
  xlab="Tamaño real", col=c("darkblue","red"),
  legend.text=c("Pred Big","Pred Small")
)
```

### Contraste de hipótesis

Como último análisis sobre el conjunto de datos, se pasa a realizar un constraste de hipótesis en el que se intentará dar una respuesta sobre el conjunto de datos a la afirmación de que los jugadores que juegan en la posición de Center obtenienen un mayor ratio de eficiencia(PER) que el resto de jugadores que juegan en el resto de posiciónes. Por lo tanto, para este análisis plantearemos que la hipótesis nula es que los jugadores del resto de las posiciones tienen un mayor o igual PER que los centers y como hipótesis alternativa la contraria:

$$
  \begin{array}{ll}
    H_{0}: &  PER_{center}=<PER_{others}\\
    H_{1}: &  PER_{center}>PER_{others}\
  \end{array}
$$

Por lo tanto, una vez planteada las hipótesis se pasa a realizar el contraste mediante la función *t.test* en el que se define como parámetros var.equal a TRUE ya que como se ha podido comprobar antes las varianzas son iguales y el parámetro conf.level con un nivel de confianza del 95%:

```{r}
# REFERENCIA: 
t.test(
  x           = playerstats$PER[playerstats$Pos=='C'],
  y           = playerstats$PER[playerstats$Pos!='C'],
  alternative = "greater",
  var.equal   = TRUE,
  conf.level  = 0.95
)
```

Tras realizar el test, podemos ver que el p-value es muy próximo a 0, por lo tanto es menor que alpha y podríamos rechazar la hipótesis nula que dice que el PER de los jugadores de la posición de center tienen un PER menor. Si visualizamos la distribución de ambos conjuntos de datos podremos observar que los jugadores en la posición de center tienen un mayor PER que el resto de jugadores:

```{r}
mean_center <- mean(playerstats$PER[playerstats$Pos=='C'])
mean_noCenter <- mean(playerstats$PER[playerstats$Pos!='C'])
par(mfrow=c(1,2))
hist(playerstats$PER[playerstats$Pos=='C'], main="PER Center", xlab = NULL, col = "lightblue")
hist(playerstats$PER[playerstats$Pos!='C'], main="PER other", xlab = NULL, col = "lightgreen")
```


# Resolución del problema

Para resolver el problema lo primero que se ha hecho es un estudio sobre la correlación de las variables con el PER, es decir, la variable que buscamos predecir. De este análisis hemos obtenido conclusiones positivas donde se confirma que todas las variables están bastante relacionadas con esta nota que se atribuye a los jugadores, algo que tiene lógica, pero hemos observado que los tiros de 3 puntos no eran demasiado necesarios. 

Tras la realización de los análisis empleados en el apartado anterior, se ha podido demostrar que, para el cálculo de la variable PER en un modelo de regresión lineal, las variables que tienen una mayor importancia son FG2p, FTp, ORB, AST y STL, descartando también los tiros de 3 puntos. Sin embargo, se ha demostrado que este modelo no se ajusta a la totalidad de los datos ya que solo se ajusta a un 56%. Adicionalmente, se ha comprobado que la inclusión en el modelo de la variable Age, que describe la edad de los jugadores, no mejora la precisión de este, demostrando que la edad no importa a la hora de obtener un mejor o peor PER.

Con respecto al modelo de regresión logística, se ha comprobado que se puede conocer el tamaño de los jugadores a partir de sus estadísticas con un 83% de precisión. Esto nos ha permitido afirmar que los jugadores tendrán una estadísticas y otras según su tamaño y que, apartir de estas, se puede conocer si son jugadores grandes o pequeños.

Por último, mediante el constraste de hipótesis, se ha visto que por normal general los jugadores que juegan en la posición de Center obtienen un mayor PER que el resto de posiciones, y por lo tanto, se ha confirmado la suposición del mundo del baloncesto en la que los jugadores de esta posición tienen un mayor PER.  

# Referencias

[1] https://www.kaggle.com/datasets/umutalpaydn/nba-20202021-season-player-stats?resource=download

[2] José Alquicira. (2017). Análisis de correlación. 2022, Junio 2, Conogasi.org Sitio web: https://conogasi.org/articulos/analisis-de-correlacion-2/

[3] https://rpubs.com/Joaquin_AR/218467

# Firma de apartados

| Contribuciones | Firma |
|-------|-------------|
| Invetigación previa | DLT y FJCZ |
| Redacción de las respuestas | DLT y FJCZ |
| Desarrollo código | DLT y FJCZ |