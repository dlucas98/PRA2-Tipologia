---
title: "PRA2-Tipologia"
author: "David Lucas, Javier Cantero"
date: "25/5/2022"
output: 
  pdf_document:
    number_sections: yes
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE}
# PAQUETES
if (!require('nortest')) install.packages('nortest'); library('nortest')
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
if (!require('pROC')) install.packages('pROC'); library('pROC')
if (!require('ResourceSelection')) install.packages('ResourceSelection'); library('ResourceSelection')
```

# Descripción del dataset  

Para llevar a cabo el desarrollo de esta práctica, se utilizará el dataset obtenido en la Práctica 1. Este dataset contiene datos de cada uno de los jugadores que hayan interactuado con la NBA durante un periodo de tiempo específico (última temporada) y recoge todas las estadísticas acumuladas. Adicionalmente, el dataset incluye la variable PER (player efficiency rating) que permite evaluar la eficiencia del jugador con respecto a las estadísticas totales de la temporada. Mediante esta variable, se podrá conocer cómo ha sido el rendimiento del jugador y poder comparar con el resto de jugadores de una manera rápida y sencilla. 

Es imporante porque demuestra que los resultados de un jugador se pueden llegar a evaluar a partir de métricas y se pueden realizar predicciones de los resultados que continuará obteniendo.

Pretende ser capaz de facilitar las predicciones de MVPs de la temporada a través de los datos de los jugadores.



# Integración y selección de los datos de interés a analizar

Para comenzar con el tratamiento de los datos, se realiza la carga del dataset creado en la primera práctica de la asignatura:

```{r}
playerstats <- read.csv("NBAPlayerStatistics_20-21.csv", stringsAsFactors = FALSE)
head(playerstats)
```

Una vez cargada la información, mostramos la cabecera de este. En los primero registros del conjunto de datos podemos observar que el jugador Aaron Gordon se encuentra dos veces debido a que el jugador fue traspasado de un equipo a otro durante el transcurso de la temporada. Ante esta situación, se ha decidido matener los dos registros ya que la información que refleja cada uno de estos se ve influida por el contexto del equipo en el que jugó el jugador.

Además del conjunto de datos creado en la prácitca anterior, se ha decidido incluir a este información adicional proveniente del conjunto de datos Nba 2020-2021 Season Player Stats del repositorio de Kaggle (https://www.kaggle.com/datasets/umutalpaydn/nba-20202021-season-player-stats?resource=download). Por lo tanto, se pasa a realizar la carga de este conjunto de datos adicional:


```{r}
playerstats2 <- read.csv("nba2021_advanced.csv", stringsAsFactors = FALSE)
summary(playerstats2)
```
De este conjunto de datos, se ha decidido seleccionar las variales de posición(POS) y edad(Age) ya que estas enriquecen el conjunto de datos creado en la primera práctica de la asignatura. Por lo tanto, se pasa a realizar la asignación a cada jugador de su posición y edad durante la temporada 2020-2021:


```{r}
# playerstats["Age"] <- playerstats2$Age[playerstats2$Player == playerstats$Nombre]
playerstats["Age"] <- NULL
playerstats["Pos"] <- NULL
for (i in 1:length(playerstats$Nombre)){
  for (j in 1:length(playerstats2$Player))
    if(playerstats$Nombre[i] == playerstats2$Player[j]){
      playerstats$Age[i] <- playerstats2$Age[j]
      playerstats$Pos[i] <- playerstats2$Pos[j]
    }
}
playerstats <- playerstats[,c(1,2,20,21,3:19)]
```


Una vez asignadas la posición y la edad a cada jugador, se pasa a realizar la reducción de variables. Analizando en conjunto de datos, podemos observar que en este se almacenan los volumenes de tiro de los jugadores, como por ejemplo, FG3 y FG3A que muestran el volumen de tiros de tres puntos anotados y lanzados. Es por esto que se ha decido reducir estas dos variables a una sola mediante el cálculo del porcentaje de tiro de tres puntos. Por lo tanto, esta reducción se realizará con respecto a los tiros de tres puntos, tiros de dos puntos y tiros libres:


```{r}
playerstats["FG2p"] <- round((playerstats["FG"] - playerstats["FG3"]) / (playerstats["FGA"] - playerstats["FG3A"]), 2)
playerstats["FG3p"] <- round(playerstats["FG3"] / playerstats["FG3A"], 2)
playerstats["FTp"] <- round(playerstats["FT"] / playerstats["FTA"], 2)
```

Para finalizar con la construcción del conjunto de datos final, se pasa a reordenar las variables para que estas mantengan el orden visual en el conjunto de datos:
```{r}
playerstats <- playerstats[,c(1:5,20,22:24,12:19,21)]
```

Para finalizar con este apartado, se muestra el resumen del conjunto de datos y la cabecera de este:
```{r}
# Resumen del conjunto de datos
summary(playerstats)

# Cabecera del conjunto de datos
head(playerstats)
```

# Limpieza de los datos

## Ceros y elementos vacíos

Se pasa a continuación a realizar la comprobación de valores nulos y vacíos dentro del conjunto de datos. En primer lugar, se comprueba la existencia de valores NaN dentro del conjunto de datos: 
```{r}
colSums(is.na(playerstats))
```
Como podemos observar, en las variables creadas anteriormente que reflejan los porcentajes de tiro, estas contienen valores NaN producto de los cálculos realizados anteriormente. Para su corrección, se va a asignar a estos valores el valor de 0.00 debido a que es al que hacen referencia:

```{r}
playerstats$`FG2p`[is.na(playerstats$`FG2p`)] <- 0.00
playerstats$`FG3p`[is.na(playerstats$`FG3p`)] <- 0.00
playerstats$`FTp`[is.na(playerstats$`FTp`)] <- 0.00
# Comprobación de que ya no hay valores NaN 
colSums(is.na(playerstats))
```
Como se puede observar, estos valores han sido eliminado del conjunto de datos. Por último, se pasa a realizar la comprobación de valores vacíos dentro de las variables:
```{r}
colSums(playerstats==""|playerstats==" ")
```

Con respecto a los valores vacíos, se puede observar que no existen. Por lo tanto, no es necesario realizar ninguna acción para su corrección.  



## Identificación y gestión de valores extremos

Se pasa a continuación a realizar la detección de outliers dentro del conjunto de datos. Para ello, únicamente se va a realizar esta detección sobre las variables que representan los minutos jugados (MP) y los partidos (G). El motivo de detectar únicamente en estas dos variables si existen outliers se debe a que por un lado podremos analizar si existen jugadores que han jugados pocos minutos o partidos en la liga con respecto al resto de jugadores, y en caso de existir, podremos eliminarlos para que no afecten a los análisis que se realizaran posteriormente. Dicho esto, se pasa a visualizar los diagramas de cajas de las variables anteriormente mencionadas:
```{r}
# Diagramas de caja
par(mfrow = c(1, 2))
box_MP <- boxplot(playerstats$MP,main="MP outliers")
box_G <- boxplot(playerstats$G,main="G outliers")
```

Como se puede observar, en ambos diagramas no existen outliers. Sin embargo, estos diagramas son útiles ya que a traves del primer percentil se puede realizar el filtro de los jugadores que han jugado pocos minutos o partidos. Por lo tanto, a partir de este se pasa a realizar la eliminación de los jugadores que en la variables MP y G, se encuentran por debajo de este percentil:

```{r}
# Percential 25 de ambas variables
box_MP$stats[2]
box_G$stats[2]
# Eliminación de registros por debajo de este percentil
playerstats <- playerstats[playerstats$MP > box_MP$stats[2],]
playerstats <- playerstats[playerstats$G > box_G$stats[2],]
```

Una vez hecho esto, el conjunto de datos obtenido y con el que se va a pasar a realizar los análisis contiene la siguiente información:
```{r}
# Resumen del conjunto de datos
summary(playerstats)

# Cabecera del conjunto de datos
head(playerstats)
```

# Análisis de los datos

## Selección de los grupos de datos que se quieren analizar/comparar

## Comprobación de la normalidad y homogeneidad de la varianza

### Comprobación de la normalidad

Para realizar la comprobación de la normalidad, se va a realizar el estudio sobre las variables numéricas que se utilizarán posteriormente en los modelos. Es decir, la variables sobre las cuales se procede a estudiar la normalidad y la homogeneidad de la varianza son *FG2p*, *FG3p*, *FTp*, *ORB*, *DRB*, *AST*, *STL*, *BLK*, *TOV*, *PF*, *PTS*, *PER*:  

```{r}
par(mfrow=c(1,2))
for(i in 7:ncol(playerstats)) {
  qqnorm(playerstats[,i],main = paste("Normal Q-Q Plot for ",colnames(playerstats)[i]))
  qqline(playerstats[,i],col="red")
  
  x <-playerstats[,i]
  plot(density(x), main=bquote(~ n == .(playerstats[,i])),
       ylab='Densidad', col='blue3', xlab='x', las=1, lwd=4)
  
  print(paste("Tests de ", colnames(playerstats)[i]))
  
  print(shapiro.test(x)$p.value)
  
}

```

Como se puede observar, tenemos variables que, mediante los gráficos Q-Q y de densidad, podemos concluir que siguen una distribución bastante normal. Estas variables serían FG2p, FTp, PF y PER. El resto, se alejan un poco de la simetría que se buscaría en este tipo de distribuciones aunque tampoco se podría descartar al 100% la normalidad.

Para confirmar esto, se podrían realizar tests de normalidad como el de Shapiro, pero al tener una cantidad de muestras muy grande (superior a 30), no nos podemos fiar demasiado de estos resultados.

Se aprecia que según estos tests ningúna variable sigue una distribución normal, ya que nos indica en todas que el p-value es menor que el coeficiente 0.05 y nos indicaría que se puede rechazar la hipótesis nula, lo que en resumen significaría que no siguen una distribución normal. 

Sin embargo, teniendo en cuenta que tenemos 437 muestras, se puede aplicar el Teorema del Límite Central, que establece que el contraste de hipótesis sobre la media de una muestra se aproxima a una distribución normal aunque la población original no siga una distribución normal, siempre que el tamaño de la muestra sea suficientemente grande.


### Homogeneidad de la varianza

Para la homogeneidad de la varianza, se va a hacer uso del test de Fligner-Killeen para su estudio. En este estudio, se va a comparar todas las variables con la variable del PER ya que esta se extrae de las anteriores. Por lo tanto, suponiendo que la hipótesis nula consiste en que ambas varianzas son iguales se para a aplicar el test:  

```{r}
for(i in 7:(ncol(playerstats)-1)) {
print(paste('Test sobre la homogeneidad',colnames(playerstats)[i],' - PER'))
flitest <- fligner.test(playerstats[,i] ~ PER, data = playerstats)
print(flitest$p.value)
}
```

Como se puede observar, en todas las variables son homogeneas con la variable PER ya que el p-valor es superior a 0.05.

## Aplicación de pruebas estadísticas para comparar los grupos de datos

### Regresión lineal, qué variables influyen más?

Debido a que el PER se calcula a partir de las variables de los volúmenes de tiro, se puede crear un modelo de predicción para predecir esta variable.

```{r}

regresion_l <- lm(PER ~ FG2p+FG3p+FTp+ORB+DRB+AST+STL+BLK+TOV, data = playerstats)
summary(regresion_l)

```

$$
  y = -6.9301 + 22.4763x_1 + 2.7066x_2 + 10.0536x_3 + 0.0312x_4 - 0.0009x_5 + 0.0175x_6 - 0.0554x_7 + 0.0280x_8 + 0.0262x_9
$$

```{r}

par(mfrow = c(1, 2))
plot(regresion_l,which = 1)
plot(regresion_l,which = 2)

```



```{r}

pred_1 <- data.frame(NO2=40,vv=2,RS=100,HR=80,LL=0.10, TMP=25)
#pred <- predict(regresion_l, pred_1, type ="response")
#head(pred)

```


```{r}
# Cogemos como datos los que se han utilizado para el modelo, ya que al crearlo se ignoran los NAs y por ello se eliminan datos.
modeldata <- model.frame(regresion_l)

# Las etiquetas se traducen en valores de 1 y 2, pero necesitamos que sean 0 y 1, por lo que se resta 1.
modeldata <- (as.numeric(modeldata$PER)-1)

```

```{r}

hoslem.test(modeldata, regresion_l$fitted.values)

```

Hemos obtenido el valor de X-squared, así como los grados de libertad y el p-value. De esta información, nos centraremos en el p-value para sacar conclusiones.  

Del p-value podemos ver si se rechaza la hipotesis nula, que se toma como que no hay diferencias entre los valores observados y los pronosticados. En caso de que se rechazase, significaría que **el modelo no está bien ajustado**. Como en este caso hemos obtenido un 0.02856 y es menor que 0.05 (valor típico de alpha que servirá para tomar como referencia a la hora de aceptar o rechazar la hipótesis nula), concluimos que el modelo no se ajusta correctamente. Esto se interpreta así porque una probabilidad inferior al 5% no nos da la suficiente confianza para aceptar la hipotesis nula.

Esta curva es un gráfico de la sensivilidad frente a 1 menos la especificidad. Se puede calcular mediante la función *roc()* del paquete *pROC* [10].  

Para calcularlo, realizaremos las predicciones sobre todos los datos del dataset que se ha utilizado para crear el modelo y finalmente se comparará con los resultados reales, para poder ver las diferencias.


Ahora probamos a introducir la variable Age para ver si el modelo mejora.

```{r}

regresion_l <- lm(PER ~ FG2p+FG3p+FTp+ORB+DRB+AST+STL+BLK+TOV+Age, data = playerstats)
summary(regresion_l)

```

$$
  y = -6.9301 + 22.4763x_1 + 2.7066x_2 + 10.0536x_3 + 0.0312x_4 - 0.0009x_5 + 0.0175x_6 - 0.0554x_7 + 0.0280x_8 + 0.0262x_9
$$

```{r}

par(mfrow = c(1, 2))
plot(regresion_l,which = 1)
plot(regresion_l,which = 2)

```



```{r}

pred_1 <- data.frame(NO2=40,vv=2,RS=100,HR=80,LL=0.10, TMP=25)
#pred <- predict(regresion_l, pred_1, type ="response")
#head(pred)

```


```{r}
# Cogemos como datos los que se han utilizado para el modelo, ya que al crearlo se ignoran los NAs y por ello se eliminan datos.
modeldata <- model.frame(regresion_l)

# Las etiquetas se traducen en valores de 1 y 2, pero necesitamos que sean 0 y 1, por lo que se resta 1.
modeldata <- (as.numeric(modeldata$PER)-1)

```

```{r}

hoslem.test(modeldata, regresion_l$fitted.values)

```

### Regresión logística

```{r}

playerstats$tamanyo<-"Small"

playerstats$tamanyo[playerstats$Pos=="C" | playerstats$Pos=="PF" | playerstats$Pos=="SF"] <- "Big"

playerstats$tamanyo <- as.factor(playerstats$tamanyo)

```

```{r}

regresion_log <- glm(formula=tamanyo~FG2p+FG3p+FTp+ORB+DRB+AST+STL+BLK+TOV, data = playerstats, family=binomial(link=logit))
summary(regresion_log)

```


```{r}

regresion_log <- glm(formula=tamanyo~FG2p+FG3p+FTp+ORB+DRB+AST+STL+BLK+TOV+Age, data = playerstats, family=binomial(link=logit))
summary(regresion_log)

```

### Estudio de correlaciones lineales


```{r}

var_mat <- data.frame(playerstats[7:18])

cor_mat <- cor(var_mat, use = "complete.obs")
cor_mat

```
Ejemplo de explicación:

En esta estación, también veremos las mayores y menores correlaciones con el resto de variables para cada contaminante.

- *PM10*:
Con las variables meteorológicas, este contaminante tiene mayor correlación con vv, siendo un -0.2420, y la menor correlación con HR, que únicamente es de -0.0262.

Con los demás contaminantes, la mayor correlación es con NO2, ya que el coeficiente es de 0.4358. En cambio, la menor correlación es con O3, con tan solo un -0.1449.

- *SO2*:
Con las variables meteorológicas, este contaminante tiene mayor correlación con vv, con un -0.2122, y la menor correlación con PRB, con sólo un 0.0084.

Con los otros contaminantes, la mayor correlación es con PM10, con un 0.4328, y la menor con O3, con un -0.2062.

- *NO2*:
Este contaminante tiene la mayor correlación con la variable RS, con un -0.3834, y la menor correlación con la variable LL, con un -0.0951. 

Respecto a los demás contaminantes, la mayor correlación la tiene con PM10, con un 0.4358, y la menor correlación con O3, con un -0.2708.

- *O3*:
El último contaminante tiene una máxima correlación con vv, con un 0.5441, y la menor con LL, con un 0.0259.

Contra los demás contaminantes, la mayor correlación es con NO2, con un -0.2708, y la menor con PM10, con un -0.1449.

### Contraste de hipótesis

Influye la edad en el rendimiento? Se ve reflejado en el PER?

Los jugadores mayores de 30 tienen una media de PER menor?

### Contraste de hipótesis (?)

Los jugadores de la posicion CENTER tienen un mejor PER? 

$$
  \begin{array}{ll}
    H_{0}: &  PER_{center}<PER_{others}\\
    H_{1}: &  PER_{center}>PER_{others}\
  \end{array}
$$



```{r}
# REFERENCIA: https://rpubs.com/Joaquin_AR/218467

t.test(
  x           = playerstats$PER[playerstats$Pos=='C'],
  y           = playerstats$PER[playerstats$Pos!='C'],
  alternative = "greater",
  var.equal   = TRUE,
  conf.level  = 0.95
)

```

Tras realizar el test, podemos ver que el pvalue es muy próximo a 0, por lo tanto es menor que alpha y podríamos rechazar la hipótesis nula que dice que el PER de los jugadores de la posición de pivot tienen un PER menor.

```{r}
08
mean_center <- mean(playerstats$PER[playerstats$Pos=='C'])
mean_noCenter <- mean(playerstats$PER[playerstats$Pos!='C'])

par(mfrow=c(1,2))
hist(playerstats$PER[playerstats$Pos=='C'], main="PER Center", xlab = NULL, col = "lightblue")
hist(playerstats$PER[playerstats$Pos!='C'], main="PER other", xlab = NULL, col = "lightgreen")

# TODO: Mirar una representación mejor

```


# Resolución del problema
